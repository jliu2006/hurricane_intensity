{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60fb975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "\n",
    "\n",
    "def getDayPosition(json_profile):\n",
    "    with open(json_profile) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        # hurricane_days['ID'] = []\n",
    "        # hurricane_days['ID'].append(data['id'])\n",
    "\n",
    "    date_set = set() # set to avoid duplicates\n",
    "    long_lat = []\n",
    "    for path in data['path']:\n",
    "        str_date = str(path['date'])\n",
    "        # separate date into year month day to add hypens in between\n",
    "        year = str_date[0:4]\n",
    "        month = str_date[4:6]\n",
    "        day = str_date[6:8]\n",
    "        new_date = year + '-' + month + '-' + day\n",
    "        date_set.add(new_date)\n",
    "\n",
    "        # trying to add 1 to datetime -- wrong format?\n",
    "        #start_day = datetime.datetime.strptime(new_date, '%y-%m-%d')\n",
    "        #end_day = start_day + datetime.timedelta(days=1)\n",
    "\n",
    "        # trying to create dictionary so that when I add a new set of long/lat coords to a date, \n",
    "            # the function will check if there is already a set of coords\n",
    "            # if there is, it will move to the next date and coord pair\n",
    "        # hurricane_days['ID'][0] = []\n",
    "        # hurricane_days['ID'][0].append(new_date)\n",
    "\n",
    "        long = path['lg'][0:4]\n",
    "        lat = path['lt'][0:4]\n",
    "        long_lat.append([long, lat])\n",
    "\n",
    "    return date_set, long_lat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fdec951",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getDayPosition('/home/fun/data/AL182012/profile.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc95bc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function that takes HDF5 lists  and output into nparray (csv file)\n",
    "#'/home/fun/hurricane_intensity/3B-HHR.MS.MRG.3IMERG.20121021-S170000-E172959.1020.V06B.HDF5'\n",
    "\n",
    "def post_processing(param, folder, full_path_filename, lonstr, latstr): # lon and lat should be read from the path name or given externally\n",
    "    '''\n",
    "        1) pick the data only in bounding  box\n",
    "        2) output to CSV with date_time\n",
    "        3) remove the downloaded hdf5 files\n",
    "    '''    \n",
    "    lon = 0\n",
    "    lat = 0\n",
    "    sign = -1.0 if 'W' in lonstr else 1.0\n",
    "    lon = sign * float(lonstr[:-1])\n",
    "    sign = -1.0 if 'S' in latstr else 1.0\n",
    "    lat = sign * float(latstr[:-1])\n",
    "            \n",
    "    x = int((lon-longitude[0])*10)\n",
    "    y = int((lat-latitude[0])*10)\n",
    "    \n",
    "    hdf_array = h5py.File(full_path_filename, 'r')\n",
    "    data = hdf_array['Grid']['precipitationCal'][:, x-5:x+5, y-5:y+5] # 10 by 10, one square degree (#1)\n",
    "\n",
    "    datestr = str(param['date'])\n",
    "    timestr = str(param['time'])\n",
    "    final = np.array([data])\n",
    "\n",
    "    pathname = folder + 'imerg_precipitation_' + datestr + '_' + timestr + '.npy'\n",
    "    np.save(pathname, final) # write np array to .npy file with pre-existing file name + datestr + timestr (#2)\n",
    "\n",
    "    os.remove(full_path_filename) # remove previous .HDF5 file (#3)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0b92104e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
